# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZtdhsoXihaeC1OVXVDKKM7SoEAp-26LX
"""

import os
import numpy as np
import torch
import cv2
from rembg import remove
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import streamlit as st


def load_model(path: str) -> YOLO:
    """Path to Our YOLOv11"""
    model = YOLO(path)
    return model

def check_defect(egg_roi):
    """Image Processing for Classification"""

    image = egg_roi.copy()

    # 1) Resize
    height, width, _ = image.shape
    target_height = 200  # ขนาด ROI เล็กกว่าต้นฉบับ
    ratio = width / height
    width = int(target_height * ratio)
    image = cv2.resize(image, (width, target_height))

    # 2) Remove background
    removed_bg = remove(image)  # ถ้าใช้ rembg
    img_ = cv2.cvtColor(removed_bg, cv2.COLOR_RGBA2RGB)

    # 3) Shape extraction
    gray_mask = cv2.cvtColor(img_, cv2.COLOR_RGB2GRAY)
    contour, _ = cv2.findContours(gray_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    ct_mask = np.zeros_like(gray_mask)
    cv2.drawContours(ct_mask, contour, -1, (255,255,255), 10)

    # 4) Image processing
    mask1 = cv2.adaptiveThreshold(gray_mask, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY_INV, 19, 12)
    mask1 = cv2.bitwise_and(mask1, cv2.bitwise_not(ct_mask))
    _, binary_mask1 = cv2.threshold(gray_mask, 175, 255, cv2.THRESH_BINARY)
    combined_mask = cv2.bitwise_or(mask1, binary_mask1)
    final_mask = cv2.bitwise_and(combined_mask, cv2.bitwise_not(ct_mask))
    texture_inpainted_image = cv2.inpaint(gray_mask, final_mask, 5, cv2.INPAINT_TELEA)

    filtered_image_1 = cv2.GaussianBlur(texture_inpainted_image, (3,3), 0)
    alpha2 = 0.65
    kernel2 = np.array([[0, -1, 0], [-1, 5.25, -1], [0, -1, 0]])
    sharpened_image = cv2.filter2D(filtered_image_1, -1, kernel2)
    blended = cv2.addWeighted(filtered_image_1, 1-alpha2, sharpened_image, alpha2, 0)
    filtered_image_3 = cv2.GaussianBlur(blended, (3,3), 1.05)

    # 5) Canny edge
    edges = cv2.Canny(filtered_image_3, 50, 160)

    # 6) Detect shape
    closing_kernel = np.ones((5,5), np.uint8)  # ลดขนาด kernel ให้เหมาะ ROI เล็ก
    closed_mask1 = cv2.morphologyEx(ct_mask, cv2.MORPH_CLOSE, closing_kernel, iterations=1)
    dilated_kernel = np.ones((3,3), np.uint8)
    dilated_shape = cv2.dilate(closed_mask1, dilated_kernel, iterations=1)
    shape_inv = cv2.bitwise_not(dilated_shape)
    detection_result = cv2.bitwise_and(edges, shape_inv)

    # 7) Result -> Change to Method 1 or Method 2
    result = np.sum(detection_result == 255)
    is_defective = result > 0

    return is_defective

def full_pipeline(source_path, output_path, model):
    """Full Pipeline"""

    # Describe Source Video
    video_cap = cv2.VideoCapture(source_path)
    frame_width  = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = video_cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0

    # For Saving Output
    fourcc = cv2.VideoWriter_fourcc(*'avc1')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

   # Colors
    GREEN = (0,255,0)
    RED   = (0,0,255)
    WHITE = (255,255,255)

    CONFIDENCE_THRESHOLD = 0.85

    frame_idx = 0
    egg_defect_status = {}
    last_centers = {}
    disappeared = {}

    next_track_id = 0
    MAX_DISAPPEAR = 25
    DIST_THRESHOLD = 50**2  # squared distance threshold

    while True:
        ret, frame = video_cap.read()
        if not ret:
            break

        # Detection
        results = model(frame)[0]
        current_boxes = []
        for box in results.boxes.data.tolist():
            x1, y1, x2, y2, conf, cls_id = box
            if conf < CONFIDENCE_THRESHOLD:
                continue
            current_boxes.append([int(x1), int(y1), int(x2), int(y2)])

        current_centers = {}
        matched_ids = set()

        for bbox in current_boxes:
            cx = (bbox[0] + bbox[2]) // 2
            cy = (bbox[1] + bbox[3]) // 2

            best_dist = float('inf')
            matched_id = None
            for tid, (lx, ly) in last_centers.items():
                dist = (cx - lx)**2 + (cy - ly)**2
                if dist < best_dist:
                    best_dist = dist
                    matched_id = tid

            if best_dist < DIST_THRESHOLD:
                track_id = matched_id
                disappeared[track_id] = 0
            else:
                track_id = next_track_id
                next_track_id += 1
                disappeared[track_id] = 0

            current_centers[track_id] = (cx, cy)
            matched_ids.add(track_id)

            # Extract ROI
            xmin, ymin, xmax, ymax = bbox
            egg_roi = frame[ymin:ymax, xmin:xmax]

            egg_defect_status.setdefault(track_id, False)
            if not egg_defect_status[track_id]:
                is_defective = check_defect(egg_roi)
                if is_defective:
                    egg_defect_status[track_id] = True
            else:
                is_defective = True

            color = RED if is_defective else GREEN
            label_text = f"ID {track_id}" + (" DEFECT" if is_defective else "")
            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)
            cv2.putText(frame, label_text, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # Update for next frame
        last_centers = current_centers

        # Count defective
        total_defective = sum(egg_defect_status.values())
        cv2.putText(frame, f"Defective Egg: {total_defective}", (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, WHITE, 2)

        writer.write(frame)
        frame_idx += 1

    video_cap.release()
    writer.release()
    print("Finished")

    return output_path